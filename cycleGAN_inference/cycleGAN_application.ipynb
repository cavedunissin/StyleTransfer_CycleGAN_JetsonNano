{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN 應用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開啟相機應用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "save_img_name = 'test.jpg'\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow('webcam', frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key==ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "    elif key==ord('s'):\n",
    "        cv2.imwrite(save_img_name, frame)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 影片串流 + 灰階"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "save_img_name = 'test.jpg'\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ############### You can do something in her ###############\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('webcam', gray)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key==ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "    elif key==ord('s'):\n",
    "        cv2.imwrite(save_img_name, frame)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 風格轉換實作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重建生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def conv_norm_relu(in_dim, out_dim, kernel_size, stride = 1, padding=0):\n",
    "    \n",
    "    layer = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size, stride, padding),\n",
    "                          nn.InstanceNorm2d(out_dim), \n",
    "                          nn.ReLU(True))\n",
    "    return layer\n",
    "\n",
    "def dconv_norm_relu(in_dim, out_dim, kernel_size, stride = 1, padding=0, output_padding=0):\n",
    "    \n",
    "    layer = nn.Sequential(nn.ConvTranspose2d(in_dim, out_dim, kernel_size, stride, padding, output_padding),\n",
    "                          nn.InstanceNorm2d(out_dim), \n",
    "                          nn.ReLU(True))\n",
    "    return layer\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim, use_dropout):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        res_block = [nn.ReflectionPad2d(1),\n",
    "                     conv_norm_relu(dim, dim, kernel_size=3)]\n",
    "        \n",
    "        if use_dropout:\n",
    "            res_block += [nn.Dropout(0.5)]\n",
    "        res_block += [nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n",
    "                      nn.InstanceNorm2d(dim)]\n",
    "\n",
    "        self.res_block = nn.Sequential(*res_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.res_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_nc=3, output_nc=3, filters=64, use_dropout=True, n_blocks=6):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # 向下採樣\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 conv_norm_relu(input_nc   , filters * 1, 7),\n",
    "                 conv_norm_relu(filters * 1, filters * 2, 3, 2, 1),\n",
    "                 conv_norm_relu(filters * 2, filters * 4, 3, 2, 1)]\n",
    "\n",
    "        # 頸脖層\n",
    "        for i in range(n_blocks):\n",
    "            model += [ResidualBlock(filters * 4, use_dropout)]\n",
    "\n",
    "        # 向上採樣\n",
    "        model += [dconv_norm_relu(filters * 4, filters * 2, 3, 2, 1, 1),\n",
    "                  dconv_norm_relu(filters * 2, filters * 1, 3, 2, 1, 1),\n",
    "                  nn.ReflectionPad2d(3),\n",
    "                  nn.Conv2d(filters, output_nc, 7),\n",
    "                  nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)    # model 是 list 但是 sequential 需要將其透過 , 分割出來\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拍照，儲存同時進行轉換，儲存兩張圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"\n",
    "torch                         1.6.0+cu101    \n",
    "torchsummary                  1.5.1          \n",
    "torchtext                     0.3.1          \n",
    "torchvision                   0.7.0+cu101\n",
    "\"\"\"\n",
    "\n",
    "def init_model():\n",
    "    \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    G_B2A = Generator().to(device)\n",
    "    G_B2A.load_state_dict(torch.load(os.path.join(\"weights\", \"netG_B2A.pth\"), map_location=device ))\n",
    "    G_B2A.eval()\n",
    "    \n",
    "    return G_B2A\n",
    "\n",
    "def test(G, img):\n",
    "    \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "    data = transform(img).to(device)\n",
    "    \n",
    "    data = data.unsqueeze(0)\n",
    "    \n",
    "    out = (0.5 * (G(data).data + 1.0)).squeeze(0)\n",
    "    \n",
    "    return out\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \n",
    "    G = init_model()\n",
    "    \n",
    "    trans_path = 'test_transform.jpg'\n",
    "    org_path = 'test_original.jpg'\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        cv2.imshow('webcam', frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key==ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        elif key==ord('s'):\n",
    "            \n",
    "            output = test(G, Image.fromarray(frame))\n",
    "            style_img = np.array(output.cpu()).transpose([1,2,0])\n",
    "            org_img = cv2.resize(frame, (256, 256))\n",
    "            \n",
    "            cv2.imwrite(trans_path, style_img*255)\n",
    "            cv2.imwrite(org_path, org_img)\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyWindow('webcam')\n",
    "    \n",
    "    # 這裡很詭異 org_img不曉得為什麼也乘到255\n",
    "    res = np.concatenate((style_img, org_img/255), axis=1)\n",
    "    cv2.imshow('res',res )\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "trans_path = 'test_transform.jpg'\n",
    "org_path = 'test_original.jpg'\n",
    "\n",
    "style_img = cv2.imread(trans_path)\n",
    "org_img = cv2.imread(org_path)\n",
    "\n",
    "res = np.concatenate((style_img, org_img), axis=1)\n",
    "cv2.imshow('res',res )\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 影像串流 + 風格轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def conv_norm_relu(in_dim, out_dim, kernel_size, stride = 1, padding=0):\n",
    "    \n",
    "    layer = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size, stride, padding),\n",
    "                          nn.InstanceNorm2d(out_dim), \n",
    "                          nn.ReLU(True))\n",
    "    return layer\n",
    "\n",
    "def dconv_norm_relu(in_dim, out_dim, kernel_size, stride = 1, padding=0, output_padding=0):\n",
    "    \n",
    "    layer = nn.Sequential(nn.ConvTranspose2d(in_dim, out_dim, kernel_size, stride, padding, output_padding),\n",
    "                          nn.InstanceNorm2d(out_dim), \n",
    "                          nn.ReLU(True))\n",
    "    return layer\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim, use_dropout):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        res_block = [nn.ReflectionPad2d(1),\n",
    "                     conv_norm_relu(dim, dim, kernel_size=3)]\n",
    "        \n",
    "        if use_dropout:\n",
    "            res_block += [nn.Dropout(0.5)]\n",
    "        res_block += [nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n",
    "                      nn.InstanceNorm2d(dim)]\n",
    "\n",
    "        self.res_block = nn.Sequential(*res_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.res_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_nc=3, output_nc=3, filters=64, use_dropout=True, n_blocks=6):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # 向下採樣\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 conv_norm_relu(input_nc   , filters * 1, 7),\n",
    "                 conv_norm_relu(filters * 1, filters * 2, 3, 2, 1),\n",
    "                 conv_norm_relu(filters * 2, filters * 4, 3, 2, 1)]\n",
    "\n",
    "        # 頸脖層\n",
    "        for i in range(n_blocks):\n",
    "            model += [ResidualBlock(filters * 4, use_dropout)]\n",
    "\n",
    "        # 向上採樣\n",
    "        model += [dconv_norm_relu(filters * 4, filters * 2, 3, 2, 1, 1),\n",
    "                  dconv_norm_relu(filters * 2, filters * 1, 3, 2, 1, 1),\n",
    "                  nn.ReflectionPad2d(3),\n",
    "                  nn.Conv2d(filters, output_nc, 7),\n",
    "                  nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)    # model 是 list 但是 sequential 需要將其透過 , 分割出來\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "torch                         1.6.0+cu101    \n",
    "torchsummary                  1.5.1          \n",
    "torchtext                     0.3.1          \n",
    "torchvision                   0.7.0+cu101\n",
    "\"\"\"\n",
    "\n",
    "def init_model():\n",
    "    \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    G_B2A = Generator().to(device)\n",
    "    G_B2A.load_state_dict(torch.load(os.path.join(\"weights\", \"netG_B2A.pth\"), map_location=device ))\n",
    "    G_B2A.eval()\n",
    "    \n",
    "    return G_B2A\n",
    "\n",
    "def test(G, img):\n",
    "    \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "    data = transform(img).to(device)\n",
    "    \n",
    "    data = data.unsqueeze(0)\n",
    "\n",
    "    out = (0.5 * (G(data).data + 1.0)).squeeze(0)\n",
    "\n",
    "\n",
    "    return out\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \n",
    "    G = init_model()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    change_style = False\n",
    "\n",
    "    save_img_name = 'test.jpg'\n",
    "    cv2text = ''\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Do Something Cool \n",
    "        ############################\n",
    "        \n",
    "        if change_style:\n",
    "            style_img = test(G, Image.fromarray(frame))\n",
    "            out = np.array(style_img.cpu()).transpose([1,2,0])\n",
    "            cv2text = 'Style Transfer'\n",
    "        else:\n",
    "            out = frame\n",
    "            cv2text = 'Original'\n",
    "            \n",
    "        out = cv2.resize(out, (512, 512))\n",
    "        out = cv2.putText(out, f'{cv2text}', (20, 40), cv2.FONT_HERSHEY_SIMPLEX ,  \n",
    "                   1, (255, 255, 255), 2, cv2.LINE_AA) \n",
    "            \n",
    "        ###########################\n",
    "        \n",
    "        cv2.imshow('webcam', out)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key==ord('q'):\n",
    "            break\n",
    "\n",
    "        elif key==ord('s'):\n",
    "            if change_style==True:\n",
    "                cv2.imwrite(save_img_name,out*255)\n",
    "            else:\n",
    "                cv2.imwrite(save_img_name,out)\n",
    "        \n",
    "        elif key==ord('t'):\n",
    "            change_style = False if change_style else True\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
