{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN 應用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開啟相機應用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "save_img_name = 'test.jpg'\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow('webcam', frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key==ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "    elif key==ord('s'):\n",
    "        cv2.imwrite(save_img_name, frame)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 影片串流 + 灰階"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "save_img_name = 'test.jpg'\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ############### You can do something in her ###############\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('webcam', gray)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key==ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "    elif key==ord('s'):\n",
    "        cv2.imwrite(save_img_name)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 影像串流+CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def conv_norm_relu(in_dim, out_dim, kernel_size, stride = 1, padding=0):\n",
    "    \n",
    "    layer = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size, stride, padding),\n",
    "                          nn.InstanceNorm2d(out_dim), \n",
    "                          nn.ReLU(True))\n",
    "    return layer\n",
    "\n",
    "def dconv_norm_relu(in_dim, out_dim, kernel_size, stride = 1, padding=0, output_padding=0):\n",
    "    \n",
    "    layer = nn.Sequential(nn.ConvTranspose2d(in_dim, out_dim, kernel_size, stride, padding, output_padding),\n",
    "                          nn.InstanceNorm2d(out_dim), \n",
    "                          nn.ReLU(True))\n",
    "    return layer\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim, use_dropout):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        res_block = [nn.ReflectionPad2d(1),\n",
    "                     conv_norm_relu(dim, dim, kernel_size=3)]\n",
    "        \n",
    "        if use_dropout:\n",
    "            res_block += [nn.Dropout(0.5)]\n",
    "        res_block += [nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n",
    "                      nn.InstanceNorm2d(dim)]\n",
    "\n",
    "        self.res_block = nn.Sequential(*res_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.res_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_nc=3, output_nc=3, filters=64, use_dropout=True, n_blocks=6):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # 向下採樣\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 conv_norm_relu(input_nc   , filters * 1, 7),\n",
    "                 conv_norm_relu(filters * 1, filters * 2, 3, 2, 1),\n",
    "                 conv_norm_relu(filters * 2, filters * 4, 3, 2, 1)]\n",
    "\n",
    "        # 頸脖層\n",
    "        for i in range(n_blocks):\n",
    "            model += [ResidualBlock(filters * 4, use_dropout)]\n",
    "\n",
    "        # 向上採樣\n",
    "        model += [dconv_norm_relu(filters * 4, filters * 2, 3, 2, 1, 1),\n",
    "                  dconv_norm_relu(filters * 2, filters * 1, 3, 2, 1, 1),\n",
    "                  nn.ReflectionPad2d(3),\n",
    "                  nn.Conv2d(filters, output_nc, 7),\n",
    "                  nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)    # model 是 list 但是 sequential 需要將其透過 , 分割出來\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"\n",
    "torch                         1.6.0+cu101    \n",
    "torchsummary                  1.5.1          \n",
    "torchtext                     0.3.1          \n",
    "torchvision                   0.7.0+cu101\n",
    "\"\"\"\n",
    "\n",
    "def init_model():\n",
    "    \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    G_B2A = Generator().to(device)\n",
    "    G_B2A.load_state_dict(torch.load(os.path.join(\"weights\", \"netG_B2A.pth\"), map_location=device ))\n",
    "    G_B2A.eval()\n",
    "    \n",
    "    return G_B2A\n",
    "\n",
    "def test(G, img):\n",
    "    \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "    data = transform(img).to(device)\n",
    "    \n",
    "    data = data.unsqueeze(0)\n",
    "    \n",
    "    out = (0.5 * (G(data).data + 1.0)).squeeze(0)\n",
    "    \n",
    "    return out\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \n",
    "    G = init_model()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    save_img_name = 'test.jpg'\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        #### Do Something Cool ####\n",
    "        \n",
    "        im_pil = Image.fromarray(frame)\n",
    "        out = test(G, im_pil)\n",
    "        \n",
    "        ###########################\n",
    "        \n",
    "        out = np.array(out).transpose([1,2,0])\n",
    "        cv2.imshow('webcam', out)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key==ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        elif key==ord('s'):\n",
    "            cv2.imwrite(save_img_name)\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-174c3a9f7d00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-174c3a9f7d00>\u001b[0m in \u001b[0;36minit_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cuda:0'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mG_B2A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mG_B2A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"netG_B2A.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mG_B2A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Generator' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"\n",
    "torch                         1.6.0+cu101    \n",
    "torchsummary                  1.5.1          \n",
    "torchtext                     0.3.1          \n",
    "torchvision                   0.7.0+cu101\n",
    "\"\"\"\n",
    "\n",
    "def init_model():\n",
    "    \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    G_B2A = Generator().to(device)\n",
    "    G_B2A.load_state_dict(torch.load(os.path.join(\"weights\", \"netG_B2A.pth\"), map_location=device ))\n",
    "    G_B2A.eval()\n",
    "    \n",
    "    return G_B2A\n",
    "\n",
    "def test(G, img):\n",
    "    \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "    data = transform(img).to(device)\n",
    "    \n",
    "    data = data.unsqueeze(0)\n",
    "    \n",
    "    out = (0.5 * (G(data).data + 1.0)).squeeze(0)\n",
    "    \n",
    "    return out\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \n",
    "    G = init_model()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    style_mode = ''\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        #### Do Something Cool ####\n",
    "        \n",
    "        im_pil = Image.fromarray(frame)\n",
    "        out = test(G, im_pil)\n",
    "        \n",
    "        ###########################\n",
    "        \n",
    "        out = np.array(out).transpose([1,2,0])\n",
    "        cv2.imshow('webcam', out)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key==ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        elif key==ord('s'):\n",
    "            cv2.imwrite('test.jpg', out)\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
